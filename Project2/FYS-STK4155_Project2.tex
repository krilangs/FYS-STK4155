\documentclass[12pt,a4paper,english]{article}
\usepackage{times}
\usepackage[utf8]{inputenc}
\usepackage{babel,textcomp}
\usepackage{mathpazo}
\usepackage{mathtools}
\usepackage{amsmath,amssymb}
\usepackage{ dsfont }
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfig} 
\usepackage[colorlinks]{hyperref}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{textcomp}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{backgroundcolor=\color{lbcolor},tabsize=4,rulecolor=,language=python,basicstyle=\scriptsize,upquote=true,aboveskip={1.5\baselineskip},columns=fixed,numbers=left,showstringspaces=false,extendedchars=true,breaklines=true,
prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},frame=single,showtabs=false,showspaces=false,showstringspaces=false,identifierstyle=\ttfamily,keywordstyle=\color[rgb]{0,0,1},commentstyle=\color[rgb]{0.133,0.545,0.133},stringstyle=\color[rgb]{0.627,0.126,0.941},literate={å}{{\r a}}1 {Å}{{\r A}}1 {ø}{{\o}}1}

% Use for references
\usepackage[sort&compress,square,comma,numbers]{natbib}
\DeclareRobustCommand{\citeext}[1]{\citeauthor{#1}~\cite{#1}}

% Fix spacing in tables and figures
%\usepackage[belowskip=-8pt,aboveskip=5pt]{caption}
%\setlength{\intextsep}{10pt plus 2pt minus 2pt}

% Change the page layout
%\usepackage[showframe]{geometry}
\usepackage{layout}
\setlength{\hoffset}{-0.6in}  % Length left
%\setlength{\voffset}{-1.1in}  % Length on top
\setlength{\textwidth}{480pt}  % Width
%\setlength{\textheight}{720pt}  % Height
%\setlength{\footskip}{25pt}

\newcommand{\VEV}[1]{\langle#1\rangle}
\title{FYS-STK 4155 Project 2}
\date{}
\author{ Kristoffer Langstad \footnote{\url{https://github.com/krilangs/FYS-STK4155}}\\ \textit{krilangs@uio.no}}

\begin{document}%\layout
\maketitle
\begin{abstract}
	...
\end{abstract}

\section{Introduction}
\label{sect:Intro}
A much used method in statistical analysis is classification with Logistic regression analysis. With this type of method we can sort large amount of data and predict outcomes of different situations. 

In this project we will develop our own logistic regression code for classification using Python to study credit card data from Taiwan taken from the Machine Learning Repository UCI \cite{UCI}. Since this data set has been previously studied in a scientific research paper by \citet{origarticle} considering data mining techniques, we will use these results in the article to compare with our results. We will also develop our own multilayer perceptron code (MLP) and Neural Network code (NN), with different gradient descent solvers and cost functions. With these methods we will classify the credit card data with the Logistic regression and Neural Network, and solve a regression problem on the Franke function with the Neural Network code. For the Franke function we compare with results from a previous project for solving the regression problem using standard least squares \cite{proj1}.

First we will look at the data sets to be evaluated in this project. This includes the Taiwan credit card data (classification) and the Franke function (regression). Then in the theory section, we look at the theory of the different methods and algorithms to be used in this project and implemented into a Python program for solving the classification and regression problems. In the methods section we look at the implementation of the methods discussed in the theory section. Here we build our code for solving the classification and regression problems. We start by reading in the credit card data. This data set is then altered to account for missing and/or wrongly implemented values and then scaled. Then we create the Logistic regressor with gradient descent solvers and cost functions to being able to reproduce the results in the scientific article \cite{origarticle}. Then we create a Feed Forward Neural Network code with back propagation and cost functions by training the network to find optimal weights and biases. We test different regularization parameters and learning rates to find the optimal accuracy score. Then we use the Neural Network code with appropriate cost function to perform a regression analysis in the Franke function data. In the Results section we compare and discuss the results we get from the Logistic regression and Neural Network analysis with use of different cost functions, gradient descent solvers, regularization parameters  and learning rates. Then we compare and discuss the results from the previous regression project for the Franke function and the regression analysis with Neural Network. In the conclusion section we come up with a critical evaluation of the various algorithms we have used in this project. From this evaluation we should find out which algorithm works best for the classification case and which is best for the regression case.

\section{Data}
\label{sect:Data}
\subsection{Classification: Credit Card Data}
The classification analysis in this project is of the Taiwan default payments credit card data downloaded from the UCI \cite{UCI} as an .xls file. The outcome of the default payment is binary as (YES=1, NO=0). The original data set contains 30 000 data points with 23 explanatory variables (24 with the output):
\begin{enumerate}
	\item X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. 
	\item X2: Gender (1 = male; 2 = female). 
	\item X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). 
	\item X4: Marital status (1 = married; 2 = single; 3 = others). 
	\item X5: Age (year). 
	\item X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. 
	\item X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. 
	\item X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005. 
\end{enumerate}
By analysis of the data set; there are errors that have to be taken into consideration where there are values that does not correspond to the values that should be given from the variables description.

\subsection{Regression: Franke's function}
The regression analysis in this project we evaluate the two-dimensional Frank function which is defined as:
\begin{align}
\label{eq:Franke_func}
f(x,y)=&\frac{3}{4}\exp\left(-\frac{(9x-2)^2}{4}-\frac{(9y-2)^2}{4}\right)+
\frac{3}{4}\exp\left(-\frac{(9x+1)^2}{49}-\frac{(9y+1)^2}{10}\right)\\ 
+& \frac{1}{2}\exp\left(-\frac{(9x-7)^2}{4}-\frac{(9y-3)^2}{4}\right)- \frac{1}{5}\exp\left(-(9x-4)^2-(9y-7)^2\right) \nonumber
\end{align}
This function is defined for $x,y\in[0,1]$, and is a widely used function for testing various interpolation and fitting algorithms. With this function we also add a normally distributed noise $\epsilon\sim \mathcal{N}(0,\sigma^2)$
\begin{equation*}
F(x,y)=f(x,y)+\epsilon.
\end{equation*}

\section{Theory}
\label{sect:Theory}
\subsection{Regression}
\label{subsect:Regression}
For the regression evaluation we will look at the $R^2$ score to evaluate the performance of the model as
\begin{equation}
\label{eq:R2_score}
R^2(\textbf{y},\tilde{\textbf{y}})=1-\frac{\sum_{i=0}^{n-1}(y_i-\tilde{y})^2}{\sum_{i=0}^{n-1}(y_i-\bar{y})^2},
\end{equation}
with model $\tilde{\textbf{y}}$ and the mean value, $\bar{y}$, of the data \textbf{y} as
\[\bar{y}=\frac{1}{n}\sum_{i=0}^{n-1}y_i.\]

\subsection{Classification}
\label{subsect:Classification}
For the classification we will measure the performance of the model with the accuracy score as
\begin{equation}
\label{eq:accuracy_score}
\text{Accuracy}=\frac{\sum_{i=1}^{n}I(t_i=y_i)}{n},
\end{equation}
with target $t_i$, model output $y_i$, number of targets $n$ and indicator function $I$ as
\[I=\begin{cases}
1, \text{ if } t_i=y_i\\
0, \text{ if } t_i\neq y_i
\end{cases}.\]
The optimal accuracy score is 1.

\subsection{Logistic Regression (LR)}
\label{subsect:LR}
In logistic regression we use linear regression in $x$ to model the posterior probabilities with sums in the domain [0,1]. Logistic regression is what is called a soft classifier. This means that it outputs the probability of a given category. For our case with logistic regression, the output is a binary case which gives either 1 if the credit card user could default the credit card debt or 0 if not. The probability that a data point $x_i$ belongs to a specific category $y_i$ can be represented by the likelihood given by the logistic (Sigmoid) function as
\begin{equation}
\label{eq:sigmoid}
p(\textbf{x})=\frac{e^{\hat{\beta}\textbf{x}}}{1+e^{\hat{\beta}\textbf{x}}},
\end{equation}
where $\hat{\beta}=[\beta_0,\beta_1,...,\beta_p]$ are the weights/predictors we want to extract from the data and $\textbf{x}=[1,x_1,x_2,...,x_p]$. The probabilities for the binary case have the following relation:
\begin{equation*}
p(y_i=0|x_i,\hat{\beta})=1-p(y_i=1|x_i,\hat{\beta})
\end{equation*}

\subsubsection{Maximum Likelihood Estimation (MLE)}
\label{subsect:MLE}
For the total likelihood for all the possible outcomes from a given dataset $\mathcal{D}=\{(y_i, x_i)\}$ with binary variables $y_i\in\{0,1\}$, that are independent and identically distributed (i.i.d.), we use the MLE principle to maximize the probability of seeing the observed data:
\begin{equation}
\label{eq:max_likelihood}
P(\mathcal{D}|\hat{\beta})=\prod_{i=1}^{n}\left[p(y_i=1|x_i,\hat{\beta})\right]^{y_i}\left[1-p(y_i=1|x_i,\hat{\beta})\right]^{1-y_i}
\end{equation}
From this likelihood we get the log-likelihood as:
\begin{equation}
\label{eq:log_likelihood}
P_{\log }(\hat{\beta})=\log[P(\mathcal{D}|\hat{\beta})]=\sum_{i=1}^{n}\left(y_i\log[p(y_i=1|x_i,\hat{\beta})]+(1-y_i)\log[1-p(y_i=1|x_i,\hat{\beta})]\right)
\end{equation}

\subsubsection{Cost function/cross-entropy}
\label{subsect:Cost_func}
For the classification problem we define the cost function as the negative of the log-likelihood as 
\begin{align}
\label{eq:cost_func}
\mathcal{C}(\hat{\beta})=-P_{\log }(\hat{\beta})= -\sum_{i=1}^{n}\left(y_i\log[p(y_i=1|x_i,\hat{\beta})]+(1-y_i)\log[1-p(y_i=1|x_i,\hat{\beta})]\right).
\end{align}
Maximization of the log-likelihood is then the same as minimizing the cost function. In statistics the cost function is also called the cross-entropy. Rewriting of the cost function (eq. \ref{eq:cost_func}) the leads to:
\begin{equation}
\label{eq:cost_func_rewritten}
\mathcal{C}(\hat{\beta})=-\sum_{i=1}^{n}\left(y_i(\textbf{x}_{i*}\hat{\beta})-\log(1+e^{\textbf{x}_{i*}\hat{\beta}})\right).
\end{equation}

The $\hat{\beta}$ parameters are found through minimization of the cost function by taking the derivative of the cost function (eq. \ref{eq:cost_func_rewritten}) with respect to the $\hat{\beta}$ values. Define vector $\textbf{y}\in\mathcal{R}^n$ for $n$ elements $y_i$, matrix $\textbf{X}\in\mathcal{R}^{n\times p}$ with $x_i$ values and vector $\textbf{p}\in\mathcal{R}^n$ for fitted probabilities $p(y_i|x_i,\hat{\beta})$ with non-linear dependence on $\hat{\beta}$. The minimized cost function becomes
\begin{equation}
\label{eq:min_cost_func}
\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}}=-\textbf{X}^T(\textbf{y}-\textbf{p}).
\end{equation}
This gives set of linear equations to solve the system for $\hat{\beta}$. Define diagonal matrix \textbf{W} with elements $p(y_i|x_i,\hat{\beta})(1-p(y_i|x_i,\hat{\beta}))$. The second derivative of the cost function, also called the Hessian matrix, is then in compact form:
\begin{equation}
\label{eq:Hessian}
\frac{\partial^2 \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}\partial \hat{\beta}^T}=\textbf{X}^T\textbf{W}\textbf{X}.
\end{equation}

The resulting equation of minimization of the cost function is non-linear, and have to be solved using minimization algorithms called gradient descent methods.

For the multilayer perceptron (MLP) (sect. \ref{subsect:MLP}), the cost function can be rewritten in terms of the weights $\textbf{W}$, biases $\textbf{b}$ and activation function $f(\textbf{z})$ as
\begin{equation}
\label{eq:cost_MLP}
\mathcal{C}(\textbf{W},\textbf{b})=-\sum_{j=1}^{n}t_j\log(p(y_j|z_j))+(1-t_j)\log(p(y_j|z_j)).
\end{equation}

For the regression problem the cost function is defined as the mean squared error (MSE)
\begin{equation}
\label{eq:MSE}
\mathcal{C}(\hat{\beta})=MSE(\hat{\beta})=\frac{1}{n}\sum_{i=1}^{n}(y_i-\textbf{x}_{i*}\hat{\beta})^2.
\end{equation}
The minimization for this cost function is
\begin{equation}
\label{eq:MSE_deriv}
\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}}=-\frac{2}{n}\textbf{X}^T(\textbf{y}-\textbf{x}\hat{\beta}).
\end{equation}

For the regression problem the cost function is the MSE (eq. \ref{eq:MSE}), while for the classification problem the cost function is the cross-entropy (eq. \ref{eq:cost_func_rewritten}).

\subsection{Gradient Descent (GD)}
\label{sect: GD}
As stated in the cost function section (\ref{subsect:Cost_func}), we will use gradient descent methods to optimize the cost function by its minimum. In GD the $\hat{\alpha}$ parameters are adjusted iteratively to the largest negative value of the gradient for a given number of iterations or until a given tolerance is reached. This is calculated as
\begin{equation}
\label{eq:GD_general}
\hat{\alpha}^{(n+1)}=\hat{\alpha}^{(n)}-\gamma\nabla_{\hat{\alpha}} \mathcal{C}(\hat{\alpha}^{(n)}),
\end{equation}
where $\gamma$ is a learning rate parameter which acts as a hyperparameter for controlling the step length. Since the cost function is to be optimized with optimal $\hat{\alpha}_{\text{opt}}$ parameters, then there is an optimal $\gamma_{\text{opt}}$ value. If $\gamma<\gamma_{\text{opt}}$, then the GD may take a long time or not even converge within the time frame or for the given number of iterations. If $\gamma>\gamma_{\text{opt}}$, then the GD may not find the minimum value/$\hat{\alpha}_{\text{opt}}$ that we want.

For logistic regression (LR) we have $\hat{\alpha}=\hat{\beta}$, such that the optimal $\hat{\beta}_{\text{opt}}$ values becomes
\begin{equation}
\label{eq:GD}
\hat{\beta}_{\text{opt}}^{(n+1)}=\hat{\beta}_{\text{opt}}^{(n)}-\frac{\partial \mathcal{C}(\hat{\beta}^{(n)})}{\partial \hat{\beta}}\left[\frac{\partial^2 \mathcal{C}(\hat{\beta}^{(n)})}{\partial \hat{\beta}\partial \hat{\beta}^T}\right]^{-1}=\hat{\beta}^{(n)}_{\text{opt}}-\gamma\frac{\partial \mathcal{C}(\hat{\beta}^{(n)})}{\partial \hat{\beta}},
\end{equation}
which can be rewritten to
\begin{equation}
\label{eq:GD_opt}
\hat{\beta}_{\text{opt}}^{(n+1)}=\hat{\beta}_{\text{opt}}^{(n)}-(\textbf{X}^T\textbf{W}\textbf{X})^{-1}(\textbf{X}^T(\textbf{p}-\textbf{y}))=\hat{\beta}_{\text{opt}}^{(n)}-\gamma(\textbf{X}^T(\textbf{p}-\textbf{y})).
\end{equation}

For the MLP (sect. \ref{subsect:MLP}) we have the parameter $\hat{\alpha}$ as the weights \textbf{W} and biases \textbf{b}.

For regression and ordinary least square (OLS) we have $\hat{\alpha}=\hat{\beta}$, which gives
\begin{equation}
\label{eq:GD_OLS}
\hat{\beta}_{\text{OLS}}^{(n+1)}=\hat{\beta}_{\text{OLS}}^{(n)}-(\textbf{X}^T\textbf{X})^{-1}(\textbf{X}^T(\textbf{x}\hat{\beta}^{(n)}-\textbf{y})).
\end{equation}

Some important things to notice about the standard GD is that; it is sensitive to initial conditions $\hat{\beta}^{(0)}_{\text{opt}}$ and choices of learning rates, it treats all directions in the parameter space uniformly, it can misinterpret a local minimum as a global minimum and normally the gradient is computationally expensive to calculate for large datasets. To improve the calculations we introduce another gradient descent method; stochastic gradient descent (STD) with mini-batches...

\subsection{Neural Networks (NN)}
\label{sect:NN}
Neural networks are computational models that are supposed to mimic biological systems, and they consist of layers of nodes that are connected. Neural networks can be used in both regression and classification problems. Neural networks have, as seen in Figure \ref{fig:Neural_network}, an input layer, a hidden layer and an output layer. This is a simple case with two input variables/nodes, one hidden layer with 4 nodes and one node in the output layer. Neural networks can contain many hidden layers, and the number of nodes in each layer have to be decided by us and may vary from layer to layer. The input and output layers contain as many nodes as there are input and output variables respectively. The number of output variables vary depending on the problem and may differ from the number of input variables. From the figure we see that the input variables are sent to the hidden layer nodes where they are processed with an activation function before sent to the output layer. The connection between the nodes are affected by weight variables $w$ which gives weighted sums to be passed through the activation function. The outputted weighted sum have to pass a certain threshold to not give zero output.

\begin{figure}[htbp]
	\centering\includegraphics[width=0.3\linewidth]{Neural_network.png}
	\caption{Schematic diagram of a simple single hidden layer, feed-forward neural network with two input nodes, four nodes in the single hidden layer and one output node.\label{fig:Neural_network}}
\end{figure} 

\subsubsection{Multilayer perceptron (MLP)}
\label{subsect:MLP}
Figure \ref{fig:Neural_network} shows a feed-forward neural network (FFNN) where the information only moves in one direction through the layers, as seen by the arrows. If all the nodes in a layer is connected to all the other nodes in the next layer, we call it a fully-connected FFNN. When there are three or more layers in the network with non-linear activation function on the nodes, then we call the network a multilayer perceptron (MLP).

The output \textbf{y} is produced with the activation function $f(\textbf{z})$ as
\[\textbf{y}=f(\textbf{Wx}+\textbf{b}),\]
with the activation 
\[\textbf{z}=\textbf{Wx}+\textbf{b},\]
where \textbf{W} are the weights, \textbf{x} are the inputs and \textbf{b} are biases in the nodes. The activation for the $i$-th node in the $l$-th layer is given as
\[z_i^l=\sum_{j=1}^{M}W^l_{ij}x_j+b_i,\]
with $M$ the number of possible inputs in node $i$ in layer $l$. The output of all the nodes in the $l$-th layer is
\[y_i^l=f^l\left(\sum_{j=1}^{N_{l-1}}W_{ij}^ly_j^{l-1}+b_i^l\right),\]
with $N_l$ the number of nodes in layer $l$.

\subsubsection{Back propagation}
\label{subsect:back_prop}
The weights and biases have to be optimized to decrease the error. This leads to the back propagation algorithm. The optimization is done by minimizing the cost function $C$ with respect to the weights and biases at the output layer $l=L$:
\begin{align*}
\frac{\partial \mathcal{C}(\textbf{W},\textbf{b})}{\partial W^L_{jk}}&=\begin{cases*}
f^{\prime}(z^L_j)a_k^{L-1}(a^L_j-t_j), \text{ for Regression}\\
f^{\prime}(z^L_j)a_k^{L-1}\frac{a^L_j-t_j}{a^L_j(1-a^L_j)}, \text{ for Classification}
\end{cases*}\\
\frac{\partial \mathcal{C}(\textbf{W},\textbf{b})}{\partial b^L_{j}}&=\delta_j^L
\end{align*}
$t_j$ are the targets as in the accuracy score equation \ref{eq:accuracy_score}. The output error $\delta^L$ is defined as:
\begin{equation*}
\delta_j^L=f^{\prime}(z^L_j)\frac{\partial \mathcal{C}(\textbf{W},\textbf{b})}{\partial a^L_j}
\end{equation*}
For the back propagation through the hidden layers, $l=L-1,L-2,...,2$, the back propagation error is computed before the weights and biases are updated at each layer:
\begin{align*}
\delta_j^l&=\sum_{k}\delta_k^{l+1}W_{kj}^{l+1}f^{\prime}(z^l_j)\\
W_{jk}^l&\leftarrow W_{jk}^l-\gamma\frac{\partial \mathcal{C}(\textbf{W},\textbf{b})}{\partial W_{jk}^l}= W_{jk}^l -\gamma \delta_j^la_k^{l-1} \\
b^l_j&\leftarrow b^l_j-\gamma\frac{\partial \mathcal{C}(\textbf{W},\textbf{b})}{\partial b_j^l}=b^l_j-\gamma\delta_j^l
\end{align*}
The parameter $\gamma$ is a learning rate parameter as in the gradient descent section (\ref{sect: GD}). From these equations it is clear that they the cost function $\mathcal{C}$ and the activation function $f(\textbf{z})$ should be differentiable. With this we calculate the optimal If the learning rate is 

\section{Methods}
\section{Results}
\section{Conclusion}
\appendix
\section{Appendix}
\label{sect:Appendix}
Link to GitHub repository:\\
\url{https://github.com/krilangs/FYS-STK4155/tree/master/Project2}

\bibliographystyle{plainnat}
\bibliography{myrefs}
\end{document}